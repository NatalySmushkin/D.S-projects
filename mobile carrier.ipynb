{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobile carrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Our goal is to develop a model that will analyze the behavior of mobile customers and recommend one of the company's call plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/datasets/users_behavior.csv')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3214 entries in the dataset, 5 columns. We've already performed the data preprocessing step in previous project, so we can move straight to creating the model.\n",
    "\n",
    "Since we are dealing with categorical target (Ultra - 1, Smart - 0) this is classification task.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split our data into three parts: training(60%), validation(20%), and test(20%). \n",
    "\n",
    "For this purpose we can use numpy.split() function. We will first shuffle the rows (df.sample(frac=1)) and then split the data into three parts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, there is another way to divide datase - to use sklearn.model_selection.train_test_split twice. First to split to train(train_size=0.8) and test(test_size=0.2). Then split 80% train again into validation(test_size = 0.25 give us 0.25 * 0.8=0.2) and train(train_size =0.75 give us 0.75 * 0.8=0.6). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid, df_test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at Decision Trees model. We'll iterate over max_depth values from 1 to 10 and check the accuracy.\n",
    "\n",
    "For consistency of results we'll set the random_state to 12345."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1\n",
      "Training set: 0.7598547717842323\n",
      "Validation set: 0.7433903576982893\n",
      "max_depth = 2\n",
      "Training set: 0.7956431535269709\n",
      "Validation set: 0.7682737169517885\n",
      "max_depth = 3\n",
      "Training set: 0.8106846473029046\n",
      "Validation set: 0.7776049766718507\n",
      "max_depth = 4\n",
      "Training set: 0.8215767634854771\n",
      "Validation set: 0.7869362363919129\n",
      "max_depth = 5\n",
      "Training set: 0.828838174273859\n",
      "Validation set: 0.7791601866251944\n",
      "max_depth = 6\n",
      "Training set: 0.8360995850622407\n",
      "Validation set: 0.7667185069984448\n",
      "max_depth = 7\n",
      "Training set: 0.8589211618257261\n",
      "Validation set: 0.7884914463452566\n",
      "max_depth = 8\n",
      "Training set: 0.8692946058091287\n",
      "Validation set: 0.7993779160186625\n",
      "max_depth = 9\n",
      "Training set: 0.8781120331950207\n",
      "Validation set: 0.8055987558320373\n",
      "max_depth = 10\n",
      "Training set: 0.8947095435684648\n",
      "Validation set: 0.7947122861586314\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,11):\n",
    "        model_tree = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "        model_tree.fit(features_train, target_train)\n",
    "\n",
    "        train_predictions=model_tree.predict(features_train)\n",
    "        valid_predictions=model_tree.predict(features_valid)\n",
    "        train_accuracy = accuracy_score(target_train, train_predictions)\n",
    "        valid_accuracy = accuracy_score(target_valid, valid_predictions)\n",
    "\n",
    "        print(\"max_depth =\", depth)\n",
    "        print(\"Training set:\", train_accuracy)\n",
    "        print(\"Validation set:\", valid_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that max_depth = 3 gives us training set accuracy: 80% and validation set: 79%. That is good result without overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check another model - Random Forest. Now we'll iterate over n_estimators values from 10 to 50 and check the accuracy again. Limit the maximum depth to 10.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10\n",
      "Training set: 0.8952282157676349\n",
      "Validation set: 0.7978227060653188\n",
      "n_estimators = 20\n",
      "Training set: 0.8952282157676349\n",
      "Validation set: 0.7993779160186625\n",
      "n_estimators = 30\n",
      "Training set: 0.8936721991701245\n",
      "Validation set: 0.7978227060653188\n",
      "n_estimators = 40\n",
      "Training set: 0.8931535269709544\n",
      "Validation set: 0.7993779160186625\n",
      "n_estimators = 50\n",
      "Training set: 0.8926348547717843\n",
      "Validation set: 0.8009331259720062\n"
     ]
    }
   ],
   "source": [
    "for estim in range(10,51,10):\n",
    "        model_forest = RandomForestClassifier(n_estimators=estim, max_depth=10, random_state=12345)\n",
    "        model_forest.fit(features_train, target_train)\n",
    "        \n",
    "        train_accuracy = model_forest.score(features_train, target_train)\n",
    "        valid_accuracy = model_forest.score(features_valid, target_valid)\n",
    "\n",
    "        print(\"n_estimators =\", estim)\n",
    "        print(\"Training set:\", train_accuracy)\n",
    "        print(\"Validation set:\", valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We think the best value here is n_estimators = 20 that gives us training set accuracy: 89% and validation set: 80%  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third model that we will train is Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 0.7116182572614108\n",
      "Validation set: 0.7045101088646968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_regression = LogisticRegression(random_state=12345)\n",
    "model_regression.fit(features_train, target_train)\n",
    "\n",
    "train_accuracy =model_regression.score(features_train, target_train)\n",
    "valid_accuracy = model_regression.score(features_valid, target_valid)\n",
    "\n",
    "print(\"Training set:\", train_accuracy)\n",
    "print(\"Validation set:\", valid_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're mainly interested in the classifier's accuracy on the validation set. All three models give us approximately the same result. So it is hard to choose the best model. \n",
    "\n",
    "Thus, let's check our models on test set that was untouched till now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier : 0.8009331259720062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_forest.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(n_estimators=20, max_depth=10, random_state=12345)\n",
    "model_forest.fit(features_train, target_train)\n",
    "\n",
    "test_accuracy = model_forest.score(features_test, target_test)\n",
    "        \n",
    "print(\"RandomForestClassifier :\", test_accuracy)\n",
    "\n",
    "dump(model_forest, 'model_forest.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 0.6905132192846034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "test_accuracy = model.score(features_test, target_test)\n",
    "        \n",
    "print(\"LogisticRegression :\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier : 0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=3, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "test_predictions=model.predict(features_test)\n",
    "test_accuracy = accuracy_score(target_test, test_predictions)\n",
    "        \n",
    "print(\"DecisionTreeClassifier :\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see Random Forest model with n_estimators equal 20 provides the best accuracy result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    449\n",
       " 1    194\n",
       " Name: is_ultra, dtype: int64,\n",
       " 0    1342\n",
       " 1     586\n",
       " Name: is_ultra, dtype: int64,\n",
       " 0    438\n",
       " 1    205\n",
       " Name: is_ultra, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['is_ultra'].value_counts(), df_train['is_ultra'].value_counts(), df_test['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the sanity check of the model. If our data was balanced we would say that if our accuracy was greater then 50% then we would say that our model is better than guessing. \n",
    "\n",
    "But we have imbalanced dataset: class '0' : 2229 and class '1' : 985. The ratio is 7:3. Using value_counts() method we can see that this ratio also takes place in training, validating and test sets. \n",
    "\n",
    "For sanity check of our imbalanced dataset should compare model accuracy with share of the biggest class. We got 80% accuracy and it was bigger then 70% (share of class '0'). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
